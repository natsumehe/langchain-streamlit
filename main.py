import streamlit as st
import os
from langchain_community.chat_models import ChatTongyi
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from langchain.agents import AgentExecutor
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents.format_scratchpad import format_log_to_str
from langchain.agents.output_parsers import ReActSingleInputOutputParser
from langchain_core.tools import render_text_description
from langchain_core.runnables import RunnableLambda

# ================== é¡µé¢é…ç½® =======================
st.set_page_config(page_title='Qwen æç®€ç‰ˆ', layout='wide')
st.title("ğŸ¤– Qwen æ™ºèƒ½åŠ©æ‰‹ (æ‰‹åŠ¨é©±åŠ¨)")

# ================== å·¦è¾¹æ é…ç½® =======================
with st.sidebar:
    st.header("é…ç½®å‚æ•°")
    api_key = st.text_input('Alibaba DashScope API Key', type='password')
    model_name = st.selectbox('é€‰æ‹©æ¨¡å‹', ('qwen-max', 'qwen-plus', 'qwen-turbo'))
    temperature = st.slider('Temperature', 0.0, 1.0, value=0.1, step=0.1)
    if st.button('æ¸…ç©ºå†å²'):
        st.session_state.clear()
        st.rerun()

# ================== é€»è¾‘åˆå§‹åŒ– =======================
message_history = StreamlitChatMessageHistory(key="chat_messages")
if "steps" not in st.session_state:
    st.session_state.steps = {}

for index, msg in enumerate(message_history.messages):
    with st.chat_message(msg.type):
        if str(index) in st.session_state.steps:
            for step in st.session_state.steps[str(index)]:
                with st.status(f"å·¥å…·è°ƒç”¨: {step[0].tool}", state="complete"):
                    st.write(step[1])
        st.write(msg.content)

# ================== æ ¸å¿ƒå¯¹è¯é€»è¾‘ =======================
prompt_input = st.chat_input(placeholder='è¯·æé—®...')

if prompt_input:
    if not api_key:
        st.info('è¯·è¾“å…¥ API Key')
        st.stop()
    
    os.environ["DASHSCOPE_API_KEY"] = api_key
    st.chat_message('human').write(prompt_input)

    # 1. å‡†å¤‡ç»„ä»¶
    llm = ChatTongyi(model_name=model_name, streaming=True, temperature=temperature)
    tools = [DuckDuckGoSearchRun(name="Search")]
    tool_desc = render_text_description(tools)
    tool_names = ", ".join([t.name for t in tools])

    # 2. æ„é€ æœ€åŸå§‹çš„ ReAct æ¨¡æ¿
    template = """Answer the following questions. You have access to:
{tools}

Use this format:
Question: {input}
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (repeat Thought/Action/Action Input/Observation)
Thought: I now know the final answer
Final Answer: the final answer

Begin!
Question: {input}
Thought: {agent_scratchpad}"""

    prompt = ChatPromptTemplate.from_template(template)

    # 3. ã€æ ¸å¿ƒä¿®å¤ã€‘ä¸ä½¿ç”¨ assignï¼Œä½¿ç”¨ RunnableLambda çº¯æ‰‹åŠ¨å¤„ç†è¾“å…¥
    # è¿™ç§æ–¹å¼ç›´æ¥é¿å¼€äº† Pydantic å¯¹å¤æ‚ Runnable ç»“æ„çš„æ ¡éªŒ
    def transform_input(x):
        return {
            "input": x["input"],
            "agent_scratchpad": format_log_to_str(x["intermediate_steps"]),
            "tools": tool_desc,
            "tool_names": tool_names
        }

    # ç»„è£…é“¾ï¼šå¤„ç†è¾“å…¥ -> å¡«å……æ¨¡æ¿ -> ä¼ ç»™æ¨¡å‹ -> è§£æè¾“å‡º
    agent_chain = RunnableLambda(transform_input) | prompt | llm | ReActSingleInputOutputParser()

    executor = AgentExecutor(
        agent=agent_chain,
        tools=tools,
        verbose=True,
        handle_parsing_errors=True,
        return_intermediate_steps=True
    )

    # 4. è¿è¡Œ
    with st.chat_message('ai'):
        st_cb = StreamlitCallbackHandler(st.container())
        try:
            # ç›´æ¥è¾“å…¥å­—å…¸
            response = executor.invoke(
                {"input": prompt_input},
                config={"callbacks": [st_cb]}
            )
            st.write(response['output'])
            new_index = str(len(message_history.messages) - 1)
            st.session_state.steps[new_index] = response['intermediate_steps']
        except Exception as e:
            st.error(f"è¿˜æ˜¯æŠ¥é”™äº†ï¼Œè¿™å¯èƒ½æ˜¯ç¯å¢ƒæ·±å±‚å†²çª: {e}")
