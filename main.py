import streamlit as st
from langchain_community.chat_models import ChatTongyi
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain.memory import ConversationBufferWindowMemory
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

# ================== é¡µé¢é…ç½® =======================
st.set_page_config(page_title='åŸºäº Streamlit çš„åƒé—®èŠå¤©æœºå™¨äºº', layout='wide')
st.title("ğŸ¤– Qwen + LangChain æ™ºèƒ½åŠ©æ‰‹")

# ================== å·¦è¾¹æ é…ç½®éƒ¨åˆ† =======================
with st.sidebar:
    st.header("é…ç½®å‚æ•°")
    api_key = st.text_input('Alibaba DashScope API Key', type='password')
    model = st.selectbox('é€‰æ‹©æ¨¡å‹', ('qwen-max', 'qwen-plus', 'qwen-turbo'))
    temperature = st.slider('Temperature', 0.0, 2.0, value=0.6, step=0.1)
    
    if st.button('æ¸…ç©ºèŠå¤©å†å²è®°å½•'):
        st.session_state.clear()
        st.rerun()

# ================== æ ¸å¿ƒé€»è¾‘åˆå§‹åŒ– =======================
# 1. åˆå§‹åŒ–æ¶ˆæ¯è®°å½•
message_history = StreamlitChatMessageHistory(key="chat_messages")

# 2. åˆå§‹åŒ–ç”¨äºå­˜å‚¨ä¸­é—´æ€è€ƒæ­¥éª¤çš„çŠ¶æ€
if "steps" not in st.session_state:
    st.session_state.steps = {}

# 3. é»˜è®¤æ¬¢è¿è¯­
if len(message_history.messages) == 0:
    message_history.add_ai_message('ä½ å¥½ï¼æˆ‘æ˜¯åŸºäºé€šä¹‰åƒé—®çš„åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ')

# æ¸²æŸ“å†å²æ¶ˆæ¯
for index, msg in enumerate(message_history.messages):
    with st.chat_message(msg.type):
        # æ¸²æŸ“è¯¥æ¶ˆæ¯å¯¹åº”çš„å·¥å…·è°ƒç”¨æ­¥éª¤ï¼ˆå¦‚æœæœ‰ï¼‰
        if str(index) in st.session_state.steps:
            for step in st.session_state.steps[str(index)]:
                with st.status(f"å·¥å…·è°ƒç”¨: {step[0].tool}", state="complete"):
                    st.write(f"è¾“å…¥: {step[0].tool_input}")
                    st.write(step[1])
        st.write(msg.content)

# ================== èŠå¤©è¾“å…¥ä¸é€»è¾‘ =======================
prompt = st.chat_input(placeholder='è¯·æé—®ï¼Œä¾‹å¦‚ï¼šç°åœ¨å·´é»çš„å¤©æ°”å¦‚ä½•ï¼Ÿ')

if prompt:
    if not api_key:
        st.info('è¯·åœ¨å·¦ä¾§è¾“å…¥ API Key ä»¥å¼€å§‹å¯¹è¯')
        st.stop()

    # å±•ç¤ºç”¨æˆ·è¾“å…¥
    st.chat_message('human').write(prompt)

    # 4. æ„å»º LLM ä¸å·¥å…·
    llm = ChatTongyi(
        model_name=model,
        api_key=api_key,
        streaming=True,
        temperature=temperature,
    )
    
    tools = [DuckDuckGoSearchRun(name='Search')]

    # 5. æ„å»º Prompt Template (å¿…é¡»åŒ…å« chat_history å’Œ agent_scratchpad)
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚ä½ å¯ä»¥é€šè¿‡æœç´¢å·¥å…·è·å–å®æ—¶ä¿¡æ¯ã€‚"),
        MessagesPlaceholder(variable_name="chat_history"), # å†å²ä¸Šä¸‹æ–‡
        ("human", "{input}"),                             # å½“å‰ç”¨æˆ·è¾“å…¥
        MessagesPlaceholder(variable_name="agent_scratchpad"), # Agent æ€è€ƒå ä½ç¬¦
    ])

    # 6. åˆå§‹åŒ– Memory (Key å¿…é¡»ä¸ Prompt ä¸­çš„å˜é‡åå¯¹åº”)
    memory = ConversationBufferWindowMemory(
        chat_memory=message_history,
        return_messages=True,
        memory_key='chat_history',
        output_key='output',
        k=5
    )

    # 7. åˆ›å»º Agent å’Œ Executor
    agent = create_openai_functions_agent(llm, tools, prompt_template)
    executor = AgentExecutor.from_agent_and_tools(
        agent=agent,
        tools=tools,
        memory=memory,
        return_intermediate_steps=True,
        handle_parsing_errors=True,
        verbose=True
    )

    # 8. æ‰§è¡Œå¹¶å±•ç¤º AI å›å¤
    with st.chat_message('ai'):
        st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=True)
        response = executor.invoke(
            {"input": prompt}, 
            config={"callbacks": [st_cb]}
        )
        
        answer = response['output']
        st.write(answer)

        # ä¿å­˜ä¸­é—´æ­¥éª¤ä»¥ä¾¿åœ¨é¡µé¢åˆ·æ–°åä¾ç„¶èƒ½æ˜¾ç¤º
        # æ³¨æ„ï¼šè¿™é‡Œå‡ 1 æ˜¯å› ä¸º invoke ç»“æŸå message_history å·²ç»å¢åŠ äº†æ–°çš„ AI æ¶ˆæ¯
        new_index = str(len(message_history.messages) - 1)
        st.session_state.steps[new_index] = response['intermediate_steps']